\SetKwProg{for}{for}{:}{end}
\SetKwProg{pgsgd}{PG-SGD}{:}{end}
\SetKwProg{each}{for each}{:}{end}
\SetKwProg{IF}{if}{:}{end}

\SetKwFunction{PathIndex}{PathIndex}
\SetKwFunction{LayoutInitialization}{LayoutInitialization}
\SetKwFunction{InitZipf}{InitZipf}
\SetKwFunction{Unif}{Unif}
\SetKwFunction{Zipf}{Zipf}
\SetKwFunction{StepCount}{StepCount}
\SetKwFunction{Path}{Path}
\SetKwFunction{StepPos}{StepPos}

\begin{algorithm}
	\pgsgd{\textbf{(}$\mathcal{G}$\textbf{)}}{
		\textbf{input:} variation graph $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathcal{P})$ \\
		%https://tex.stackexchange.com/questions/22643/how-to-write-letters-in-bold-in-the-math-mode
		\textbf{output:} $N$-dimensional layout $\mathcal{L}$ with $|\mathcal{V}|$ nodes \\
		$\mathcal{XP}$ $\gets \PathIndex(\mathcal{G})$ \tcp{for path position lookup} 
		%\boldsymbol{$Z$} $\gets ZipfZetas(G,P)$ \\ %@Andrea is this correct like this?
		$\mathcal{L}$ $\gets \LayoutInitialization(\mathcal{V}, N)$ \\ %\tcp{random or deterministic} 
		$\mathcal{Z} \gets \InitZipf(\mathcal{G},\mathcal{XP})$ \tcp{Zipfian distribution}
		% atomic positions initialization?
		% TODO for simplicity reasons I would only describe the 2D one here
		\for{$\eta$ $in$ $annealing$ $schedule$}{ %our "schedule" actually is the number paths.... we should specify this I would say
			\each{$planned$ $term$ $update$} { % I think we can remove i<j, because we don't care about that
				$s_a \gets \Unif(\mathcal{XP})$ \tcp{uniformly sample a step from $\mathcal{P}$}
				$p \gets \Path(s_a,\mathcal{XP})$ \tcp{path of $s_a$}
				\uIf{$(cooling$ $||$ $flip)$} {
					$s_b \gets \Unif(\StepCount(p, \mathcal{XP}))$ \tcp{uniformly sample a step from $p$}
				} \Else {
					$s_b \gets \Zipf(p)$ \tcp{Zipfian sampling of a step from $p$}
				}
				$p_a \gets \StepPos(s_a)$ \tcp{nuc. position}
				$p_b \gets \StepPos(s_b)$ \tcp{nuc. position}
				$nd \gets ||p_a - p_b||$ \tcp{nuc. distance} %mag is nx
				$ld \gets ||\mathcal{L}_{a}-\mathcal{L}_b||$ \tcp{layout distance}
				$w_{ab} \gets \frac{1.0}{nd}$ \tcp{term weight} 
				$\mu \gets w_{ab}\eta$ \tcp{learning rate}  % current learning rate is given by term weight and step size
				\IF{$\mu>1$} {
				$\mu \gets 1$
				}
				$\delta \gets \mu \cdot \frac{ld -nd}{2}$ \tcp{the actual delta}
				\uIf{$\delta <= 0$} {
					$STOP$ \tcp{we can't optimize more}
				}
				% TODO stop early?
				% TODO potentially store new delta max?
				$r \gets \delta - ld$ \tcp{size of the term update}
				$\mathcal{L}_a \gets \mathcal{L}_a - r\cdot ld$ \tcp{update the 1st node}
				$\mathcal{L}_b \gets \mathcal{L}_b - r\cdot ld$ \tcp{update the 2nd node}
			}
		}
	}
	\caption{Pseudocode of the PG-SGD algorithm.}
	\label{alg:pg_sgd}
\end{algorithm}