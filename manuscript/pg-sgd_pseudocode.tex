\SetKwProg{for}{for}{:}{end}
\SetKwProg{pgsgd}{PG-SGD}{:}{end}
\SetKwProg{each}{for each}{:}{end}
\SetKwProg{IF}{if}{:}{end}

\SetKwFunction{PathIndex}{PathIndex}
\SetKwFunction{LayoutInitialization}{LayoutInitialization}
\SetKwFunction{InitZipf}{InitZipf}
\SetKwFunction{Unif}{Unif}
\SetKwFunction{Zipf}{Zipf}
\SetKwFunction{StepCount}{StepCount}
\SetKwFunction{Path}{Path}
\SetKwFunction{StepPos}{StepPos}

\begin{algorithm}
	\pgsgd{\textbf{(}$\mathcal{G}$\textbf{)}}{
		\textbf{input:} variation graph $\mathcal{G} = (\mathcal{V}, \mathcal{E}, \mathcal{P})$ \\
		%https://tex.stackexchange.com/questions/22643/how-to-write-letters-in-bold-in-the-math-mode
		\textbf{output:} $N$-dimensional layout $\mathcal{L}$ with $|\mathcal{V}|$ nodes \\
		$\mathcal{XP}$ $\gets \PathIndex(\mathcal{G})$ \tcp{for path position lookup} 
		%\boldsymbol{$Z$} $\gets ZipfZetas(G,P)$ \\ %@Andrea is this correct like this?
		$\mathcal{L}$ $\gets \LayoutInitialization(\mathcal{V}, N)$ \\ %\tcp{random or deterministic} 
		$\mathcal{Z} \gets \InitZipf(\mathcal{G},\mathcal{XP})$ \tcp{Zipfian distribution}
		% atomic positions initialization?
		% TODO for simplicity reasons I would only describe the 2D one here
		\for{$\eta$ $in$ $annealing$ $schedule$}{ %our "schedule" actually is the number paths.... we should specify this I would say
			\each{$planned$ $term$ $update$} { % I think we can remove i<j, because we don't care about that
				$s_i \gets \Unif(\mathcal{XP})$ \tcp{uniform sampling of a step from $\mathcal{P}$}
				$p \gets \Path(s_i,\mathcal{XP})$ \tcp{path of $s_i$}
				\uIf{$(cooling$ $||$ $flip)$} {
					$s_j \gets \Unif(\StepCount(p, \mathcal{XP}))$ \tcp{uniform sampling of a step from $p$}
				} \Else {
					$s_j \gets \Zipf(p)$ \tcp{Zipfian sampling of a step from $p$}
				}
				$p_i \gets \StepPos(s_i)$ \tcp{nuc. position}
				$p_j \gets \StepPos(s_j)$ \tcp{nuc. position}
				$nd_{ij} \gets ||p_i - p_j||$ \tcp{nuc. distance} %mag is nx
				$ld_{ij} \gets ||l_{i} - l_j||$ \tcp{layout distance}
				$w_{ij} \gets \frac{1.0}{nd_{ij}}$ \tcp{term weight} 
				$\mu \gets w_{ij}\eta$ \tcp{learning rate}  % current learning rate is given by term weight and step size
				\IF{$\mu>1$} {
				$\mu \gets 1$
				}
				$\delta \gets abs(\mu \cdot \frac{ld_{ij} -nd_{ij}}{2})$ \tcp{the actual delta}
				\uIf{$\delta <= 0$} {
					$STOP$ \tcp{we can't optimize more}
				}
				% TODO stop early?
				% TODO potentially store new delta max?
				$r \gets \delta - ld_{ij}$ \tcp{size of the update}
				$l_i \gets l_i + r\cdot ld_{ij}$ \tcp{update $v_i$ coordinates}
				$l_j \gets l_j - r\cdot ld_{ij}$ \tcp{update $v_j$ coordinates}
			}
		}
	}
	\caption{Pseudocode of PG-SGD.}
	\label{alg:pg_sgd}
\end{algorithm}